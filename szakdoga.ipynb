{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from pandas import to_datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "\n",
    "# load the train data\n",
    "dataframe = read_csv('dataset/train.csv',usecols=[i for i in range(0,211)], engine='python', header=0)\n",
    "trainData = dataframe.values\n",
    "trainDataOriginal = np.nan_to_num(trainData)\n",
    "trainData = trainDataOriginal\n",
    "# load the test data\n",
    "dataframe = read_csv('dataset/test_2.csv',usecols=[i for i in range(0,146)], engine='python', header=0)\n",
    "testData = dataframe.values\n",
    "testData = np.nan_to_num(testData)\n",
    "testX = testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "batch_size = 64\n",
    "input_dim  = 146\n",
    "output_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(625, 64, 146)\n",
      "(625, 64, 64)\n",
      "(1875, 64, 146)\n"
     ]
    }
   ],
   "source": [
    "#Separate the train data to input and output\n",
    "trainX = trainData[0:len(trainData),0:146]\n",
    "trainY = trainData[0:len(trainData),147:211]\n",
    "# normalize the dataset\n",
    "scalerInput = MinMaxScaler(feature_range=(0, 1))\n",
    "scalerOutput = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "trainX = scalerInput.fit_transform(trainX)\n",
    "trainY = scalerOutput.fit_transform(trainY)\n",
    "testX = scalerInput.fit_transform(testX)\n",
    "\n",
    "#Put it into batches\n",
    "trainX = np.reshape(trainX,(len(trainX)/batch_size,batch_size,trainX.shape[1]))\n",
    "trainY = np.reshape(trainY,(len(trainY)/batch_size,batch_size,trainY.shape[1]))\n",
    "testX  = np.reshape(testX,(len(testX)/batch_size,batch_size,testX.shape[1]))\n",
    "\n",
    "print trainX.shape\n",
    "print trainY.shape\n",
    "print testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.activations import linear\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Model\n",
    "\n",
    "class Model:\n",
    "    \n",
    "    def __init__(self, trainX, trainY):\n",
    "        self.optimizer = adam(0.01, 0.01, 0.001, 1e-08, 0.0)\n",
    "        self.model = Sequential()\n",
    "        self.model.add(LSTM(output_dim, input_shape=(batch_size, input_dim), return_sequences=True))\n",
    "        self.model.add(Dense(output_dim, activation='linear'))\n",
    "        #Configures the model for training.\n",
    "        self.model.compile(loss=\"mean_squared_error\",optimizer=self.optimizer)\n",
    "        #Trains the model for a fixed number of epochs (iterations on a dataset).\n",
    "        self.model.fit(trainX,trainY,batch_size=batch_size,epochs=1)\n",
    "        #Make predictions\n",
    "    \n",
    "    def predict(self,testX):\n",
    "        return self.model.predict(testX)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "625/625 [==============================] - 3s - loss: 0.0968     \n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "nn = Model(trainX, trainY)\n",
    "testY = nn.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.25258470e-02  -2.28753686e-02  -2.16194876e-02 ...,  -6.20678008e-01\n",
      "    2.19840460e+12   2.53691350e+12]\n",
      " [ -2.21500136e-02  -2.27742940e-02  -2.14728676e-02 ...,  -5.83657146e-01\n",
      "    2.20374709e+12   2.57295699e+12]\n",
      " [ -2.20421813e-02  -2.27500163e-02  -2.15244908e-02 ...,  -5.74804306e-01\n",
      "    2.24092409e+12   2.62375395e+12]\n",
      " ..., \n",
      " [ -2.20589526e-02  -2.27065384e-02  -2.16787029e-02 ...,  -5.80184162e-01\n",
      "    2.25153909e+12   2.54162292e+12]\n",
      " [ -2.20447853e-02  -2.27398518e-02  -2.15612538e-02 ...,  -5.78059971e-01\n",
      "    2.22378197e+12   2.57035521e+12]\n",
      " [ -2.20487919e-02  -2.27191467e-02  -2.16432773e-02 ...,  -5.70059180e-01\n",
      "    2.21202429e+12   2.55801190e+12]]\n"
     ]
    }
   ],
   "source": [
    "testY = testY.reshape(len(testData),output_dim)\n",
    "testY = scalerOutput.inverse_transform(testY)\n",
    "print testY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the result.txt\n",
    "f1=open('./result.txt', 'w+')\n",
    "f1.write(\"Id,Predicted\\n\")\n",
    "for y in range(5):\n",
    "    for x in range(testY.shape[1]-2):\n",
    "        f1.write(str(y+1)+\"_\"+str(x+1)+\",\"+str(testY[y][x])+\"\\n\")\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
